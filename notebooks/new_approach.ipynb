{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-19cd6743ae6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_preparer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS_to_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_to_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincidence_to_hyperedges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepare_node_hyperneighbors_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from src.data_preparer import S_to_A, S_to_B, incidence_to_hyperedges, prepare_node_hyperneighbors_map\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2519\n"
     ]
    }
   ],
   "source": [
    "inputfilePath = \"/home2/e1-313-15477/ego-Facebook.edges\"\n",
    "edgelist=[]\n",
    "f = open(inputfilePath, \"r\")\n",
    "for line in f:\n",
    "    a = int(line.split(' ')[0].strip())  # \\t\n",
    "    b = int(line.split(' ')[1].strip())\n",
    "    if (a!= b):\n",
    "        edge=[a,b]\n",
    "        edgelist.append(edge)\n",
    "f.close()\n",
    "graph = nx.Graph()\n",
    "graph.add_edges_from(edgelist)\n",
    "adj=nx.adj_matrix(graph)\n",
    "A=adj\n",
    "test_pairs = list(zip(*triu(A).nonzero()))\n",
    "print(len(test_pairs))\n",
    "G = nx.from_scipy_sparse_matrix(A)\n",
    "S=nx.incidence_matrix(G)\n",
    "times=[]\n",
    "for i in range(2519):\n",
    "    times.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 748/2515 [00:00<00:00, 3690.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going for a structural split\n",
      "Converting S to A\n",
      "STEP 1: Computing SS^T\n",
      "STEP 3: Setting diagonals to 0\n",
      "STEP 4: Eliminating zeros\n",
      "Splitting into train/test...\n",
      "STEP 1: Sampling test edges...\n",
      "STEP 2: Preparing test data...\n",
      "Filling in A_test...\n",
      "STEP 3: Preparing train data...\n",
      "Filling in A_train...\n",
      "Generating negative patterns until 2515 are found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2515/2515 [00:00<00:00, 4247.33it/s]\n",
      "100%|██████████| 5038/5038 [00:00<00:00, 446553.33it/s]\n",
      "100%|██████████| 2519/2519 [00:00<00:00, 484609.29it/s]\n",
      "100%|██████████| 503/503 [00:00<00:00, 105497.30it/s]\n",
      "Predictor:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting incidence matrix to hyperedge <class 'set'> for faster processing...\n",
      "Precomputing node-hyperneighbor map...\n",
      "Splitting hyperedges and getting S_train...\n",
      "LP DATA STATS: S_train.shape = (333, 2280), A_test.nnz = 1006\n",
      "Preparing predictor AA\n",
      "Performing prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Predictor:  10%|█         | 1/10 [00:01<00:10,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Preparing predictor AS\n",
      "Performing prediction...\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predictor:  30%|███       | 3/10 [00:02<00:05,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing predictor CN\n",
      "Performing prediction...\n",
      "Done\n",
      "Preparing predictor Cos\n",
      "Performing prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Predictor:  40%|████      | 4/10 [00:03<00:04,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Preparing predictor PA\n",
      "Performing prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Predictor:  50%|█████     | 5/10 [00:03<00:03,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Preparing predictor JC\n",
      "Performing prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Predictor:  60%|██████    | 6/10 [00:04<00:03,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Preparing predictor MxO\n",
      "Performing prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Predictor:  70%|███████   | 7/10 [00:05<00:02,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Preparing predictor MnO\n",
      "Performing prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Predictor:  80%|████████  | 8/10 [00:05<00:01,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Preparing predictor NM\n",
      "Performing prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Predictor:  90%|█████████ | 9/10 [00:06<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Preparing predictor Prn\n",
      "Performing prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predictor: 100%|██████████| 10/10 [00:07<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "weighted_lp_data = prepare_lp_data(S, True, times, lp_data_params['rho'],lp_data_params['neg_factor'],lp_data_params['neg_mode'] )\n",
    "weighted_linkpred_scores_df = get_linkpred_scores(weighted_lp_data, True, linkpred_indices)\n",
    "unweighted_linkpred_scores_df = get_linkpred_scores(weighted_lp_data, False, linkpred_indices)\n",
    "unweighted_linkpred_cols = list(unweighted_linkpred_scores_df.columns)\n",
    "cols_map = {c: 'w_{}'.format(c) for c in unweighted_linkpred_cols}\n",
    "weighted_linkpred_scores_df = weighted_linkpred_scores_df.rename(columns=cols_map)\n",
    "weighted_linkpred_cols = list(weighted_linkpred_scores_df.columns)\n",
    "hyg_scores_df = get_hypergraph_scores(weighted_lp_data, hypergraph_score_indices)\n",
    "hyg_scores_cols = list(hyg_scores_df.columns)\n",
    "scores_df = pd.merge(unweighted_linkpred_scores_df, weighted_linkpred_scores_df, left_index=True, right_index=True)\n",
    "scores_df = pd.merge(scores_df, hyg_scores_df, left_index=True, right_index=True)\n",
    "pos_pairs = set(zip(*weighted_lp_data['A_test_pos'].nonzero()))\n",
    "scores_df['label'] = scores_df.index.map(lambda x: int(x in pos_pairs))\n",
    "perf_df = get_perf_df(scores_df, unweighted_linkpred_cols + weighted_linkpred_cols, hyg_scores_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perf_df and scores_df ...... end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GWH ...... functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_GWH_classification_temp(scores_df,params, G_feats, W_feats, H_feats, classifier):\n",
    "    feat_combs = [G_feats, W_feats, H_feats, G_feats + H_feats, W_feats + H_feats]\n",
    "    params['classifier_params'] = {'classifier': classifier}\n",
    "    classifier_outputs = {}\n",
    "    for comb in (feat_combs):\n",
    "        params['classifier_params']['features'] = comb\n",
    "        classifier_outputs[tuple(comb)] = perform_classification_temp(scores_df,params['data_params'],\n",
    "                                   params['lp_data_params'],\n",
    "                                   params['lp_params'],\n",
    "                                   params['classifier_params'],\n",
    "                                   params['iter_var'])\n",
    "    return classifier_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_classification_temp(scores_df,data_params, lp_data_params, lp_params, classifier_params, iter_var=0):\n",
    "    features, classifier = [classifier_params[x] for x in ['features', 'classifier']]\n",
    "    classifier_output = classify_temp(scores_df, features, classifier, iter_var)\n",
    "    return classifier_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_temp(scores_df, predictor_cols, classifier, iter_var=0):\n",
    "    df = scores_df.copy(deep=True)\n",
    "\n",
    "    if predictor_cols is None:\n",
    "        predictor_cols = list(df.columns[:-1])\n",
    "\n",
    "    X, y = df.loc[:, predictor_cols], df.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=iter_var)\n",
    "\n",
    "    if classifier == 'xgboost':\n",
    "        # data_dmatrix = xgb.DMatrix(data=X_train, label=y_train)\n",
    "        xg_reg = xgb.XGBClassifier()\n",
    "        xg_reg.fit(X_train, y_train)\n",
    "\n",
    "        # test_preds = xg_reg.predict(X_test)\n",
    "        # train_preds = xg_reg.predict(X_train)\n",
    "\n",
    "        test_probs = [i[1] for i in xg_reg.predict_proba(X_test)]\n",
    "        train_probs = [i[1] for i in xg_reg.predict_proba(X_train)]\n",
    "\n",
    "        feat_imp_df = pd.DataFrame({'importance': dict(zip(list(X.columns), xg_reg.feature_importances_))})\n",
    "\n",
    "        train_col = '{}_{}'.format(classifier, 'train')\n",
    "        test_col = '{}_{}'.format(classifier, 'test')\n",
    "\n",
    "        test_df = df.loc[X_test.index, :]\n",
    "        train_df = df.loc[X_train.index, :]\n",
    "\n",
    "        train_df[train_col] = train_probs\n",
    "        test_df[test_col] = test_probs\n",
    "\n",
    "        train_perf_df = get_perf_df(train_df[[train_col, 'label']], [train_col], [])\n",
    "        test_perf_df = get_perf_df(test_df[[test_col, 'label']], [test_col], [])\n",
    "        return {'train_perf': train_perf_df,\n",
    "                'test_perf': test_perf_df,\n",
    "                'test_scores': test_df[[test_col]],\n",
    "                'feat_imp': feat_imp_df}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GWH ...... functions ... end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.10s/it]\n"
     ]
    }
   ],
   "source": [
    "mcm = mixed_combinations_map\n",
    "outputs = {}\n",
    "for lp_col in tqdm(default_lp_cols):\n",
    "    G_feats = [lp_col]\n",
    "    W_feats = ['w_{}'.format(lp_col)]\n",
    "    H_feats = mcm[lp_col][1:]\n",
    "    outputs[lp_col] = perform_GWH_classification_temp(scores_df,params, G_feats, W_feats, H_feats, 'xgboost')\n",
    "G_feats1 = default_lp_cols\n",
    "W_feats1 = ['w_{}'.format(c) for c in default_lp_cols]\n",
    "H_feats1 = default_hyper_cols\n",
    "#outputs[default_lp_cols] = perform_GWH_classification_temp(scores_df,params, G_feats, W_feats, H_feats, 'xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for csv gephi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = get_default_params()\n",
    "data_name = 'email-Enron'\n",
    "split_mode = 'temporal'\n",
    "params['data_params']['data_name'] = data_name\n",
    "params['data_params']['split_mode'] = split_mode\n",
    "dfs = []\n",
    "i = 0\n",
    "params['iter_var'] = 1\n",
    "weighted_lp_data,lp_results = perform_link_prediction(params['data_params'], params['lp_data_params'],\n",
    "                                        params['lp_params'],params['iter_var'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name, base_path, split_mode, max_size_limit = [data_params[x] for x in\n",
    "                                                        ['data_name', 'base_path', 'split_mode', 'max_size_limit']]\n",
    "\n",
    "rho, neg_factor, neg_mode = [lp_data_params[x] for x in\n",
    "                             ['rho', 'neg_factor', 'neg_mode']]\n",
    "\n",
    "S, times, id_label_map = parse_S(data_name,\n",
    "                                 base_path,\n",
    "                                 split_mode,\n",
    "                                 max_size_limit,\n",
    "                                 *get_time_filter_params(data_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'phillip.allen@enron.com',\n",
       " 1: 'john.arnold@enron.com',\n",
       " 2: 'harry.arora@enron.com',\n",
       " 3: 'robert.badeer@enron.com',\n",
       " 4: 'susan.bailey@enron.com',\n",
       " 5: 'eric.bass@enron.com',\n",
       " 6: 'don.baughman@enron.com',\n",
       " 7: 'sally.beck@enron.com',\n",
       " 8: 'robert.benson@enron.com',\n",
       " 9: 'ynn.blair@enron.com',\n",
       " 10: 'sandra.brawner@enron.com',\n",
       " 11: 'rick.buy@enron.com',\n",
       " 12: 'larry.campbell@enron.com',\n",
       " 13: 'mike.carson@enron.com',\n",
       " 14: 'michelle.cash@enron.com',\n",
       " 15: 'onika.causholli@enron.com',\n",
       " 16: 'shelley.corman@enron.com',\n",
       " 17: 'sean.crandall@enron.com',\n",
       " 18: 'martin.cuilla@enron.com',\n",
       " 19: 'jeff.dasovich@enron.com',\n",
       " 20: 'dana.davis@enron.com',\n",
       " 21: 'craig.dean@enron.com',\n",
       " 22: 'david.delainey@enron.com',\n",
       " 23: 'james.derrick@enron.com',\n",
       " 24: 'stacy.dickson@enron.com',\n",
       " 25: 'tom.donohoe@enron.com',\n",
       " 26: 'lindy.donoho@enron.com',\n",
       " 27: 'chris.dorland@enron.com',\n",
       " 28: 'frank.ermis@enron.com',\n",
       " 29: 'daren.farmer@enron.com',\n",
       " 30: 'mark.fisher@enron.com',\n",
       " 31: 'john.forney@enron.com',\n",
       " 32: 'drew.fossum@enron.com',\n",
       " 33: 'lisa.gang@enron.com',\n",
       " 34: 'rob.gay@enron.com',\n",
       " 35: 'tracy.geaccone@enron.com',\n",
       " 36: 'chris.germany@enron.com',\n",
       " 37: 'doug.gilbert-smith@enron.com',\n",
       " 38: 'darron.giron@enron.com',\n",
       " 39: 'john.griffith@enron.com',\n",
       " 40: 'mike.grigsby@enron.com',\n",
       " 41: 'mark.guzman@enron.com',\n",
       " 42: 'mark.haedicke@enron.com',\n",
       " 43: 'mary.hain@enron.com',\n",
       " 44: 'steven.harris@enron.com',\n",
       " 45: 'rod.hayslett@enron.com',\n",
       " 46: 'marie.heard@enron.com',\n",
       " 47: 'scott.hendrickson@enron.com',\n",
       " 48: 'judy.hernandez@enron.com',\n",
       " 49: 'john.hodge@enron.com',\n",
       " 50: 'keith.holst@enron.com',\n",
       " 51: 'stanley.horton@enron.com',\n",
       " 52: 'kevin.hyatt@enron.com',\n",
       " 53: 'dan.hyvl@enron.com',\n",
       " 54: 'tana.jones@enron.com',\n",
       " 55: 'vince.kaminski@enron.com',\n",
       " 56: 'steven.kean@enron.com',\n",
       " 57: 'peter.keavey@enron.com',\n",
       " 58: 'kam.keiser@enron.com',\n",
       " 59: 'jeff.king@enron.com',\n",
       " 60: 'louise.kitchen@enron.com',\n",
       " 61: 'tori.kuykendall@enron.com',\n",
       " 62: 'john.lavorato@enron.com',\n",
       " 63: 'kenneth.lay@enron.com',\n",
       " 64: 'matthew.lenhart@enron.com',\n",
       " 65: 'andrew.lewis@enron.com',\n",
       " 66: 'eric.linder@enron.com',\n",
       " 67: 'michelle.lokay@enron.com',\n",
       " 68: 'teb.lokey@enron.com',\n",
       " 69: 'phillip.love@enron.com',\n",
       " 70: 'paul.lucci@enron.com',\n",
       " 71: 'mike.maggi@enron.com',\n",
       " 72: 'kay.mann@enron.com',\n",
       " 73: 'thomas.martin@enron.com',\n",
       " 74: 'larry.may@enron.com',\n",
       " 75: 'danny.mccarty@enron.com',\n",
       " 76: 'mike.mcconnell@enron.com',\n",
       " 77: 'brad.mckay@enron.com',\n",
       " 78: 'jonathan.mckay@enron.com',\n",
       " 79: 'errol.mclaughlin@enron.com',\n",
       " 80: 'steven.merris@enron.com',\n",
       " 81: 'albert.meyers@enron.com',\n",
       " 82: 'patrice.mims@enron.com',\n",
       " 83: 'matt.motley@enron.com',\n",
       " 84: 'scott.neal@enron.com',\n",
       " 85: 'gerald.nemec@enron.com',\n",
       " 86: 'stephanie.panus@enron.com',\n",
       " 87: 'joe.parks@enron.com',\n",
       " 88: 'susan.pereira@enron.com',\n",
       " 89: 'debra.perlingiere@enron.com',\n",
       " 90: 'vladi.pimenov@enron.com',\n",
       " 91: 'phillip.platter@enron.com',\n",
       " 92: 'kevin.presto@enron.com',\n",
       " 93: 'joe.quenet@enron.com',\n",
       " 94: 'dutch.quigley@enron.com',\n",
       " 95: 'bill.rapp@enron.com',\n",
       " 96: 'jay.reitmeyer@enron.com',\n",
       " 97: 'cooper.richey@enron.com',\n",
       " 98: 'andrea.ring@enron.com',\n",
       " 99: 'richard.ring@enron.com',\n",
       " 100: 'robin.rodrigue@enron.com',\n",
       " 101: 'benjamin.rogers@enron.com',\n",
       " 102: 'kevin.ruscitti@enron.com',\n",
       " 103: 'elizabeth.sager@enron.com',\n",
       " 104: 'eric.saibi@enron.com',\n",
       " 105: 'holden.salisbury@enron.com',\n",
       " 106: 'monique.sanchez@enron.com',\n",
       " 107: 'richard.sanders@enron.com',\n",
       " 108: 'diana.scholtes@enron.com',\n",
       " 109: 'darrell.schoolcraft@enron.com',\n",
       " 110: 'jim.schwieger@enron.com',\n",
       " 111: 'susan.scott@enron.com',\n",
       " 112: 'cara.semperger@enron.com',\n",
       " 113: 'sara.shackleton@enron.com',\n",
       " 114: 'jeffrey.shankman@enron.com',\n",
       " 115: 'richard.shapiro@enron.com',\n",
       " 116: 'hunter.shively@enron.com',\n",
       " 117: 'jeff.skilling@enron.com',\n",
       " 118: 'ryan.slinger@enron.com',\n",
       " 119: 'matt.smith@enron.com',\n",
       " 120: 'geir.solberg@enron.com',\n",
       " 121: 'steven.south@enron.com',\n",
       " 122: 'theresa.staab@enron.com',\n",
       " 123: 'carol.stclair@enron.com',\n",
       " 124: 'james.steffes@enron.com',\n",
       " 125: 'joe.stepenovitch@enron.com',\n",
       " 126: 'chris.stokley@enron.com',\n",
       " 127: 'geoff.storey@enron.com',\n",
       " 128: 'fletcher.sturm@enron.com',\n",
       " 129: 'mike.swerzbin@enron.com',\n",
       " 130: 'kate.symes@enron.com',\n",
       " 131: 'mark.taylor@enron.com',\n",
       " 132: 'jane.tholt@enron.com',\n",
       " 133: 'paul.thomas@enron.com',\n",
       " 134: 'judy.townsend@enron.com',\n",
       " 135: 'barry.tycholiz@enron.com',\n",
       " 136: 'kim.ward@enron.com',\n",
       " 137: 'kimberly.watson@enron.com',\n",
       " 138: 'v.weldon@enron.com',\n",
       " 139: 'greg.whalley@enron.com',\n",
       " 140: 'stacey.white@enron.com',\n",
       " 141: 'mark.whitt@enron.com',\n",
       " 142: 'jason.williams@enron.com',\n",
       " 143: 'bill.williams@enron.com',\n",
       " 144: 'jason.wolfe@enron.com',\n",
       " 145: \"paul.y'barbo@enron.com\",\n",
       " 146: 'andy.zipper@enron.com',\n",
       " 147: 'john.zufferli@enron.com'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_edge_list(weighted_lp_data,lp_results,algo):\n",
    "    test_edges = set(zip(*weighted_lp_data['A_test'].nonzero()))\n",
    "    traing_edges = set(zip(*weighted_lp_data['A_train'].nonzero()))\n",
    "    edges=test_edges.union(traing_edges)\n",
    "    df_test = pd.DataFrame(test_edges) \n",
    "    df_train = pd.DataFrame(traing_edges) \n",
    "    df_edges = pd.DataFrame(edges) \n",
    "    attribute_test=lp_results['scores'][algo]\n",
    "    return (df_test,df_train,df_edges)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo=['CN','AS']\n",
    "a,b,c=node_edge_list(weighted_lp_data,lp_results,algo)\n",
    "\n",
    "a.columns = ['Source', 'Target']\n",
    "b.columns = ['Source', 'Target']\n",
    "c.columns = ['Source', 'Target']\n",
    "a.to_csv(\"test_edges.csv\",index=False)\n",
    "b.to_csv(\"train_edges.csv\",index=False)\n",
    "c.to_csv(\"edges.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.to_csv(\"test_edges.csv\",index=False,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>observed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5161</td>\n",
       "      <td>20</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5162</td>\n",
       "      <td>40</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5163</td>\n",
       "      <td>77</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5164</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5165</td>\n",
       "      <td>116</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5166 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1  observed\n",
       "0     135   78         0\n",
       "1      20   25         0\n",
       "2      74  106         0\n",
       "3      83   61         0\n",
       "4       6   28         0\n",
       "...   ...  ...       ...\n",
       "5161   20   51         1\n",
       "5162   40  135         1\n",
       "5163   77   62         1\n",
       "5164   60   90         1\n",
       "5165  116  111         1\n",
       "\n",
       "[5166 rows x 3 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['observed']=0\n",
    "b['observed']=1\n",
    "pd.concat([a,b]).reset_index().drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for csv gephi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA</th>\n",
       "      <th>AS</th>\n",
       "      <th>CN</th>\n",
       "      <th>Cos</th>\n",
       "      <th>PA</th>\n",
       "      <th>JC</th>\n",
       "      <th>MxO</th>\n",
       "      <th>MnO</th>\n",
       "      <th>NM</th>\n",
       "      <th>Prn</th>\n",
       "      <th>...</th>\n",
       "      <th>HASl1</th>\n",
       "      <th>HASl2</th>\n",
       "      <th>HASl3</th>\n",
       "      <th>HAAm</th>\n",
       "      <th>HAAM</th>\n",
       "      <th>HAAa</th>\n",
       "      <th>HAAs</th>\n",
       "      <th>HAAl1</th>\n",
       "      <th>HAAl2</th>\n",
       "      <th>HAAl3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>1.135233</td>\n",
       "      <td>0.125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.590616</td>\n",
       "      <td>0.212351</td>\n",
       "      <td>2.123513</td>\n",
       "      <td>2.123513</td>\n",
       "      <td>0.967611</td>\n",
       "      <td>0.967611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>1.135233</td>\n",
       "      <td>0.125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.590616</td>\n",
       "      <td>0.212351</td>\n",
       "      <td>2.123513</td>\n",
       "      <td>2.123513</td>\n",
       "      <td>0.967611</td>\n",
       "      <td>0.967611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>(1, 7)</td>\n",
       "      <td>1.135233</td>\n",
       "      <td>0.125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.590616</td>\n",
       "      <td>0.212351</td>\n",
       "      <td>2.123513</td>\n",
       "      <td>2.123513</td>\n",
       "      <td>0.967611</td>\n",
       "      <td>0.967611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>0.513898</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.191612</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>0.513898</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.191612</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>(3, 4)</td>\n",
       "      <td>1.235246</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.766449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>(3, 6)</td>\n",
       "      <td>0.513898</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.191612</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>(3, 7)</td>\n",
       "      <td>0.513898</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.191612</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>1.235246</td>\n",
       "      <td>0.200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.525226</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.766449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>(4, 6)</td>\n",
       "      <td>0.513898</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.191612</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.513898</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.191612</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>(4, 8)</td>\n",
       "      <td>1.235246</td>\n",
       "      <td>0.200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.525226</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.766449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              AA     AS   CN       Cos    PA        JC   MxO  MnO        NM  \\\n",
       "(1, 2)  1.135233  0.125  2.0  0.500000  16.0  0.333333  0.50  0.5  0.500000   \n",
       "(1, 6)  1.135233  0.125  2.0  0.500000  16.0  0.333333  0.50  0.5  0.500000   \n",
       "(1, 7)  1.135233  0.125  2.0  0.500000  16.0  0.333333  0.50  0.5  0.500000   \n",
       "(2, 3)  0.513898  0.125  1.0  0.353553   8.0  0.200000  0.25  0.5  0.316228   \n",
       "(2, 4)  0.513898  0.125  1.0  0.353553   8.0  0.200000  0.25  0.5  0.316228   \n",
       "(3, 4)  1.235246  0.500  2.0  1.000000   4.0  1.000000  1.00  1.0  1.000000   \n",
       "(3, 6)  0.513898  0.125  1.0  0.353553   8.0  0.200000  0.25  0.5  0.316228   \n",
       "(3, 7)  0.513898  0.125  1.0  0.353553   8.0  0.200000  0.25  0.5  0.316228   \n",
       "(3, 8)  1.235246  0.200  2.0  0.632456  10.0  0.400000  0.40  1.0  0.525226   \n",
       "(4, 6)  0.513898  0.125  1.0  0.353553   8.0  0.200000  0.25  0.5  0.316228   \n",
       "(4, 7)  0.513898  0.125  1.0  0.353553   8.0  0.200000  0.25  0.5  0.316228   \n",
       "(4, 8)  1.235246  0.200  2.0  0.632456  10.0  0.400000  0.40  1.0  0.525226   \n",
       "\n",
       "             Prn  ...     HASl1     HASl2     HASl3      HAAm      HAAM  \\\n",
       "(1, 2)  0.000000  ...  0.458333  0.208333  0.208333  0.000000  0.590616   \n",
       "(1, 6)  0.000000  ...  0.458333  0.208333  0.208333  0.000000  0.590616   \n",
       "(1, 7)  0.000000  ...  0.458333  0.208333  0.208333  0.000000  0.590616   \n",
       "(2, 3)  0.000000  ...  0.083333  0.083333  0.083333  0.000000  0.383224   \n",
       "(2, 4)  0.000000  ...  0.083333  0.083333  0.083333  0.000000  0.383224   \n",
       "(3, 4)  1.000000  ...  0.222222  0.222222  0.222222  0.766449  0.766449   \n",
       "(3, 6)  0.000000  ...  0.083333  0.083333  0.083333  0.000000  0.383224   \n",
       "(3, 7)  0.000000  ...  0.083333  0.083333  0.083333  0.000000  0.383224   \n",
       "(3, 8)  0.447214  ...  0.222222  0.222222  0.222222  0.000000  0.766449   \n",
       "(4, 6)  0.000000  ...  0.083333  0.083333  0.083333  0.000000  0.383224   \n",
       "(4, 7)  0.000000  ...  0.083333  0.083333  0.083333  0.000000  0.383224   \n",
       "(4, 8)  0.447214  ...  0.222222  0.222222  0.222222  0.000000  0.766449   \n",
       "\n",
       "            HAAa      HAAs     HAAl1     HAAl2     HAAl3  \n",
       "(1, 2)  0.212351  2.123513  2.123513  0.967611  0.967611  \n",
       "(1, 6)  0.212351  2.123513  2.123513  0.967611  0.967611  \n",
       "(1, 7)  0.212351  2.123513  2.123513  0.967611  0.967611  \n",
       "(2, 3)  0.191612  0.383224  0.383224  0.383224  0.383224  \n",
       "(2, 4)  0.191612  0.383224  0.383224  0.383224  0.383224  \n",
       "(3, 4)  0.766449  0.766449  0.766449  0.766449  0.766449  \n",
       "(3, 6)  0.191612  0.383224  0.383224  0.383224  0.383224  \n",
       "(3, 7)  0.191612  0.383224  0.383224  0.383224  0.383224  \n",
       "(3, 8)  0.383224  0.766449  0.766449  0.766449  0.766449  \n",
       "(4, 6)  0.191612  0.383224  0.383224  0.383224  0.383224  \n",
       "(4, 7)  0.191612  0.383224  0.383224  0.383224  0.383224  \n",
       "(4, 8)  0.383224  0.766449  0.766449  0.766449  0.766449  \n",
       "\n",
       "[12 rows x 92 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([unweighted_linkpred_scores_df.T, weighted_linkpred_scores_df.rename(columns = {c: 'w_{}'.format(c) for c in weighted_linkpred_scores_df.columns}).T, hyg_df.T]).T\n",
    "# df = unweighted_linkpred_scores_df.copy()\n",
    "# df = hyg_df.copy()\n",
    "df.index = map(lambda x: (x[0]+1, x[1]+1), df.index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experimenter import mixed_combinations_map as mcm\n",
    "\n",
    "approaches = list(mcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a7d6c9950>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "approach = approaches[2]\n",
    "columns = mcm[approach] + ['w_{}'.format(approach)]\n",
    "df1 = df[columns].sort_values(approach, ascending=False)\n",
    "fig, ax = plt.subplots(figsize = (20, 10))data:image/png;base64,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\n",
    "df1.plot(kind='bar', ax=ax, grid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AS 3.39015461809847\n",
      "HASM 3.4552570819816015\n",
      "HASa 3.2737372088322316\n",
      "HASl1 3.229067773571208\n",
      "HASl2 3.4386014660562387\n"
     ]
    }
   ],
   "source": [
    "from information_calculator import get_entropy\n",
    "columns = mcm[approach]\n",
    "for col in columns:\n",
    "    scores = np.array(list(df[col]))\n",
    "    print(col, get_entropy(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkpred_indices=[0, 1, 2, 5, 6, 8, 10, 11, 12, 13]\n",
    "hypergraph_score_indices=[8, 9, 11, 12, 30, 31, 33, 34, 52, 53, 55, 56, 37, 38, 40, 41, 14, 16, 17, 19, 20, 1, 2, 4, 5, 66, 67, 69, 70, 59, 60, 62, 63, 44, 45, 47, 48, 23, 24, 26, 27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "default_lp_cols = ['AA', 'AS', 'CN', 'Cos', 'PA', 'JC', 'MxO', 'MnO', 'NM', 'Prn']\n",
    "abbr_pred_map = {a: p for p, a in predictor_abbr_map.items()}\n",
    "default_lp_names = [abbr_pred_map[a] for a in default_lp_cols]\n",
    "default_lp_indices = [all_predictor_names.index(p) for p in default_lp_names]\n",
    "\n",
    "metrics = ['ap', 'auc', 'p@+', 'p@10', 'p@100', 'r@+', 'r@10', 'r@100']\n",
    "default_hyper_cols = ['HAAM', 'HAAa', 'HAAl1', 'HAAl2',\n",
    "                      'HASM', 'HASa', 'HASl1', 'HASl2',\n",
    "                      'HCNM', 'HCNa', 'HCNl1', 'HCNl2',\n",
    "                      'HCosM', 'HCosa', 'HCosl1', 'HCosl2',\n",
    "                      'HDPa', 'HPM', 'HPa', 'HPl1', 'HPl2',\n",
    "                      'HJCM', 'HJCa', 'HJCl1', 'HJCl2',\n",
    "                      'HmaxoM', 'HmaxoA', 'Hmaxol1', 'Hmaxol2',\n",
    "                      'HminoM', 'HminoA', 'Hminol1', 'Hminol2',\n",
    "                      'HNMM', 'HNMa', 'HNMl1', 'HNMl2',\n",
    "                      'HPearM', 'HPeara', 'HPearl1', 'HPearl2',\n",
    "                      ]\n",
    "hyg_abbr_pred_map = {a: p for p, a in hypergraph_score_abbr_map.items()}\n",
    "default_hyg_names = [hyg_abbr_pred_map[a] for a in default_hyper_cols]\n",
    "default_hyper_indices = [all_hypergraph_score_names.index(p) for p in default_hyg_names]\n",
    "\n",
    "combined_tables = {}\n",
    "mixed_combinations_map = {'AA': ['AA', 'HAAM', 'HAAa', 'HAAl1', 'HAAl2'],\n",
    "                          'AS': ['AS', 'HASM', 'HASa', 'HASl1', 'HASl2'],\n",
    "                          'CN': ['CN', 'HCNM', 'HCNa', 'HCNl1', 'HCNl2'],\n",
    "                          'Cos': ['Cos', 'HCosM', 'HCosa', 'HCosl1', 'HCosl2'],\n",
    "                          'PA': ['PA', 'HDPa', 'HPM', 'HPa', 'HPl1', 'HPl2'],\n",
    "                          'JC': ['JC', 'HJCM', 'HJCa', 'HJCl1', 'HJCl2'],\n",
    "                          'Kz': ['Kz', 'HKz'],\n",
    "                          'MxO': ['MxO', 'HmaxoM', 'HmaxoA', 'Hmaxol1', 'Hmaxol2'],\n",
    "                          'MnO': ['MnO', 'HminoM', 'HminoA', 'Hminol1', 'Hminol2'],\n",
    "                          'NM': ['NM', 'HNMM', 'HNMa', 'HNMl1', 'HNMl2'],\n",
    "                          'Prn': ['Prn', 'HPearM', 'HPeara', 'HPearl1', 'HPearl2'], }\n",
    "from src.utils import get_library_path\n",
    "\n",
    "library_path = get_library_path()\n",
    "sys.path.append(library_path)\n",
    "sys.path.append(os.path.join(library_path, 'hynetworkx'))\n",
    "from linkpred import linkpred\n",
    "import pandas as pd\n",
    "from scipy.sparse import triu\n",
    "import networkx as nx\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "base_path = '/content/gdrive/My Drive/Colab Notebooks/data/'\n",
    "\n",
    "all_predictor_names = ['AdamicAdar',  # 0\n",
    "                       'AssociationStrength',  # 1\n",
    "                       'CommonNeighbours',  # 2\n",
    "                       'Community',  # 3\n",
    "                       'Copy',  # 4\n",
    "                       'Cosine',  # 5\n",
    "                       'DegreeProduct',  # 6\n",
    "                       'GraphDistance',  # 7\n",
    "                       'Jaccard',  # 8\n",
    "                       'Katz',  # 9\n",
    "                       'MaxOverlap',  # 10\n",
    "                       'MinOverlap',  # 11\n",
    "                       'NMeasure',  # 12\n",
    "                       'Pearson',  # 13\n",
    "                       'Random',  # 14\n",
    "                       'ResourceAllocation',  # 15\n",
    "                       'RootedPageRank',  # 16\n",
    "                       'SimRank',  # 17\n",
    "                       ]\n",
    "\n",
    "# all_predictor_names = ['Random','AdamicAdar', 'CommonNeighbours', 'Cosine', 'DegreeProduct', 'Jaccard', 'Katz',\n",
    "# 'SimRank']\n",
    "predictor_abbr_map = {'AdamicAdar': 'AA',\n",
    "                      'AssociationStrength': 'AS',\n",
    "                      'CommonNeighbours': 'CN',\n",
    "                      'Community': 'Comm',\n",
    "                      'Copy': 'Cpy',\n",
    "                      'Cosine': 'Cos',\n",
    "                      'DegreeProduct': 'PA',\n",
    "                      'GraphDistance': 'GD',\n",
    "                      'Jaccard': 'JC',\n",
    "                      'Katz': 'Kz',\n",
    "                      'MaxOverlap': 'MxO',\n",
    "                      'MinOverlap': 'MnO',\n",
    "                      'NMeasure': 'NM',\n",
    "                      'Pearson': 'Prn',\n",
    "                      'Random': 'Rnd',\n",
    "                      'ResourceAllocation': 'RA',\n",
    "                      'RootedPageRank': 'RPR',\n",
    "                      'SimRank': 'SR'}\n",
    "\n",
    "all_predictors = [eval('linkpred.predictors.{}'.format(x)) for x in all_predictor_names]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import triu\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "from src.data_preparer import S_to_A, S_to_B, incidence_to_hyperedges, prepare_node_hyperneighbors_map\n",
    "from src.utils import get_library_path, get_base_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 1, 1, 1, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 1, 1, 1, 1],\n",
       "        [1, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 1, 1, 1],\n",
       "        [0, 1, 0, 0, 1, 0, 1, 1],\n",
       "        [0, 1, 0, 0, 1, 1, 0, 1],\n",
       "        [1, 1, 0, 0, 1, 1, 1, 0]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predictor: 100%|██████████| 10/10 [00:00<00:00, 316.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "0\n",
      "Preparing predictor AA\n",
      "Performing prediction...\n",
      "Done\n",
      "1\n",
      "Preparing predictor AS\n",
      "Performing prediction...\n",
      "Done\n",
      "2\n",
      "Preparing predictor CN\n",
      "Performing prediction...\n",
      "Done\n",
      "3\n",
      "Preparing predictor Cos\n",
      "Performing prediction...\n",
      "Done\n",
      "4\n",
      "Preparing predictor PA\n",
      "Performing prediction...\n",
      "Done\n",
      "5\n",
      "Preparing predictor JC\n",
      "Performing prediction...\n",
      "Done\n",
      "6\n",
      "Preparing predictor MxO\n",
      "Performing prediction...\n",
      "Done\n",
      "7\n",
      "Preparing predictor MnO\n",
      "Performing prediction...\n",
      "Done\n",
      "8\n",
      "Preparing predictor NM\n",
      "Performing prediction...\n",
      "Done\n",
      "9\n",
      "Preparing predictor Prn\n",
      "Performing prediction...\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "weighted_linkpred_scores_df = get_linkpred_scores1(weighted_lp_data, True,A, G,linkpred_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predictor: 100%|██████████| 10/10 [00:00<00:00, 691.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Preparing predictor AA\n",
      "Performing prediction...\n",
      "Done\n",
      "Preparing predictor AS\n",
      "Performing prediction...\n",
      "Done\n",
      "Preparing predictor CN\n",
      "Performing prediction...\n",
      "Done\n",
      "Preparing predictor Cos\n",
      "Performing prediction...\n",
      "Done\n",
      "Preparing predictor PA\n",
      "Performing prediction...\n",
      "Done\n",
      "Preparing predictor JC\n",
      "Performing prediction...\n",
      "Done\n",
      "Preparing predictor MxO\n",
      "Performing prediction...\n",
      "Done\n",
      "Preparing predictor MnO\n",
      "Performing prediction...\n",
      "Done\n",
      "Preparing predictor NM\n",
      "Performing prediction...\n",
      "Done\n",
      "Preparing predictor Prn\n",
      "Performing prediction...\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unweighted_linkpred_scores_df = get_linkpred_scores1(weighted_lp_data, False, A,G,linkpred_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Hmaxom</th>\n",
       "      <th>HmaxoM</th>\n",
       "      <th>HmaxoA</th>\n",
       "      <th>Hmaxos</th>\n",
       "      <th>Hmaxol1</th>\n",
       "      <th>Hmaxol2</th>\n",
       "      <th>Hmaxol3</th>\n",
       "      <th>HPearm</th>\n",
       "      <th>HPearM</th>\n",
       "      <th>HPeara</th>\n",
       "      <th>...</th>\n",
       "      <th>HASl1</th>\n",
       "      <th>HASl2</th>\n",
       "      <th>HASl3</th>\n",
       "      <th>HAAm</th>\n",
       "      <th>HAAM</th>\n",
       "      <th>HAAa</th>\n",
       "      <th>HAAs</th>\n",
       "      <th>HAAl1</th>\n",
       "      <th>HAAl2</th>\n",
       "      <th>HAAl3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"3\" valign=\"top\">0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.559017</td>\n",
       "      <td>0.559017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.590616</td>\n",
       "      <td>0.212351</td>\n",
       "      <td>2.123513</td>\n",
       "      <td>2.123513</td>\n",
       "      <td>0.967611</td>\n",
       "      <td>0.967611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.559017</td>\n",
       "      <td>0.559017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.590616</td>\n",
       "      <td>0.212351</td>\n",
       "      <td>2.123513</td>\n",
       "      <td>2.123513</td>\n",
       "      <td>0.967611</td>\n",
       "      <td>0.967611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.559017</td>\n",
       "      <td>0.559017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.590616</td>\n",
       "      <td>0.212351</td>\n",
       "      <td>2.123513</td>\n",
       "      <td>2.123513</td>\n",
       "      <td>0.967611</td>\n",
       "      <td>0.967611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.191612</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.191612</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"4\" valign=\"top\">2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.766449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.191612</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.191612</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.766449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"3\" valign=\"top\">3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.191612</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.191612</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.383224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.766449</td>\n",
       "      <td>0.766449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Hmaxom    HmaxoM    HmaxoA    Hmaxos   Hmaxol1   Hmaxol2   Hmaxol3  \\\n",
       "0 1  0.000000  0.250000  0.125000  1.250000  1.250000  0.559017  0.559017   \n",
       "  5  0.000000  0.250000  0.125000  1.250000  1.250000  0.559017  0.559017   \n",
       "  6  0.000000  0.250000  0.125000  1.250000  1.250000  0.559017  0.559017   \n",
       "1 2  0.000000  0.250000  0.125000  0.250000  0.250000  0.250000  0.250000   \n",
       "  3  0.000000  0.250000  0.125000  0.250000  0.250000  0.250000  0.250000   \n",
       "2 3  0.666667  0.666667  0.666667  0.666667  0.666667  0.666667  0.666667   \n",
       "  5  0.000000  0.250000  0.125000  0.250000  0.250000  0.250000  0.250000   \n",
       "  6  0.000000  0.250000  0.125000  0.250000  0.250000  0.250000  0.250000   \n",
       "  7  0.000000  0.666667  0.333333  0.666667  0.666667  0.666667  0.666667   \n",
       "3 5  0.000000  0.250000  0.125000  0.250000  0.250000  0.250000  0.250000   \n",
       "  6  0.000000  0.250000  0.125000  0.250000  0.250000  0.250000  0.250000   \n",
       "  7  0.000000  0.666667  0.333333  0.666667  0.666667  0.666667  0.666667   \n",
       "\n",
       "       HPearm    HPearM    HPeara  ...     HASl1     HASl2     HASl3  \\\n",
       "0 1  0.000000  0.000000  0.000000  ...  0.458333  0.208333  0.208333   \n",
       "  5  0.000000  0.000000  0.000000  ...  0.458333  0.208333  0.208333   \n",
       "  6  0.000000  0.000000  0.000000  ...  0.458333  0.208333  0.208333   \n",
       "1 2  0.000000  0.000000  0.000000  ...  0.083333  0.083333  0.083333   \n",
       "  3  0.000000  0.000000  0.000000  ...  0.083333  0.083333  0.083333   \n",
       "2 3  0.466667  0.466667  0.466667  ...  0.222222  0.222222  0.222222   \n",
       "  5  0.000000  0.000000  0.000000  ...  0.083333  0.083333  0.083333   \n",
       "  6  0.000000  0.000000  0.000000  ...  0.083333  0.083333  0.083333   \n",
       "  7  0.000000  0.466667  0.233333  ...  0.222222  0.222222  0.222222   \n",
       "3 5  0.000000  0.000000  0.000000  ...  0.083333  0.083333  0.083333   \n",
       "  6  0.000000  0.000000  0.000000  ...  0.083333  0.083333  0.083333   \n",
       "  7  0.000000  0.466667  0.233333  ...  0.222222  0.222222  0.222222   \n",
       "\n",
       "         HAAm      HAAM      HAAa      HAAs     HAAl1     HAAl2     HAAl3  \n",
       "0 1  0.000000  0.590616  0.212351  2.123513  2.123513  0.967611  0.967611  \n",
       "  5  0.000000  0.590616  0.212351  2.123513  2.123513  0.967611  0.967611  \n",
       "  6  0.000000  0.590616  0.212351  2.123513  2.123513  0.967611  0.967611  \n",
       "1 2  0.000000  0.383224  0.191612  0.383224  0.383224  0.383224  0.383224  \n",
       "  3  0.000000  0.383224  0.191612  0.383224  0.383224  0.383224  0.383224  \n",
       "2 3  0.766449  0.766449  0.766449  0.766449  0.766449  0.766449  0.766449  \n",
       "  5  0.000000  0.383224  0.191612  0.383224  0.383224  0.383224  0.383224  \n",
       "  6  0.000000  0.383224  0.191612  0.383224  0.383224  0.383224  0.383224  \n",
       "  7  0.000000  0.766449  0.383224  0.766449  0.766449  0.766449  0.766449  \n",
       "3 5  0.000000  0.383224  0.191612  0.383224  0.383224  0.383224  0.383224  \n",
       "  6  0.000000  0.383224  0.191612  0.383224  0.383224  0.383224  0.383224  \n",
       "  7  0.000000  0.766449  0.383224  0.766449  0.766449  0.766449  0.766449  \n",
       "\n",
       "[12 rows x 72 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 34521.02it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 12037.77it/s]\n",
      "Hypergraph score:   0%|          | 0/12 [00:00<?, ?it/s]\n",
      "Test pair: 100%|██████████| 12/12 [00:00<00:00, 16567.36it/s]\n",
      "\n",
      "Test pair: 100%|██████████| 12/12 [00:00<00:00, 11809.40it/s]\n",
      "\n",
      "Test pair: 100%|██████████| 12/12 [00:00<00:00, 57000.73it/s]\n",
      "\n",
      "Test pair: 100%|██████████| 12/12 [00:00<00:00, 7042.35it/s]\n",
      "\n",
      "Test pair: 100%|██████████| 12/12 [00:00<00:00, 3078.20it/s]\n",
      "\n",
      "Test pair: 100%|██████████| 12/12 [00:00<00:00, 13425.35it/s]\n",
      "\n",
      "Matrix power:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Test pair: 100%|██████████| 12/12 [00:00<00:00, 1803.61it/s]\n",
      "\n",
      "\n",
      "Test pair: 100%|██████████| 12/12 [00:00<00:00, 4599.86it/s]\n",
      "\n",
      "\n",
      "Test pair: 100%|██████████| 12/12 [00:00<00:00, 4643.57it/s]\n",
      "\n",
      "\n",
      "Test pair: 100%|██████████| 12/12 [00:00<00:00, 3147.50it/s]\n",
      "\n",
      "\n",
      "Test pair: 100%|██████████| 12/12 [00:00<00:00, 4737.10it/s]\n",
      "Matrix power: 100%|██████████| 5/5 [00:00<00:00, 77.22it/s]\n",
      "Hypergraph score:  58%|█████▊    | 7/12 [00:00<00:00, 40.81it/s]\n",
      "Test pair: 100%|██████████| 12/12 [00:00<00:00, 15069.36it/s]\n",
      "\n",
      "Test pair:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting incidence matrix to hyperedge <class 'set'> for faster processing...\n",
      "Precomputing node-hyperneighbor map...\n",
      "Calculating hypergraph scores: HyperMaxOverlap\n",
      "Calculating hypergraph scores: HyperPearson\n",
      "Calculating hypergraph scores: HyperDegreeProduct\n",
      "Calculating hypergraph scores: HyperCommonNeighbour\n",
      "Calculating hypergraph scores: HyperNMeasure\n",
      "Calculating hypergraph scores: HyperJaccard\n",
      "Calculating hypergraph scores: HyperKatz\n",
      "Finding A and B from S\n",
      "Iterating over matrix powers...\n",
      "Calculating hypergraph scores: HyperMinOverlap\n",
      "Calculating hypergraph scores: HyperProduct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test pair: 100%|██████████| 12/12 [00:00<00:00, 13464.86it/s]\n",
      "\n",
      "Test pair: 100%|██████████| 12/12 [00:00<00:00, 11259.88it/s]\n",
      "\n",
      "Test pair: 100%|██████████| 12/12 [00:00<00:00, 14984.12it/s]\n",
      "\n",
      "Test pair: 100%|██████████| 12/12 [00:00<00:00, 4774.85it/s]\n",
      "Hypergraph score: 100%|██████████| 12/12 [00:00<00:00, 56.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating hypergraph scores: HyperCosine\n",
      "Calculating hypergraph scores: HyperAssociationStrength\n",
      "Calculating hypergraph scores: HyperAdamicAdar\n"
     ]
    }
   ],
   "source": [
    "hyg_df = get_hypergraph_scores1(weighted_lp_data,A,S, score_indices=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "sys.path.append('../')\n",
    "from src.utils import get_data_abbr, mkdir_p, get_base_path, get_library_path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "library_path = get_library_path()\n",
    "sys.path.append(library_path)\n",
    "sys.path.append(os.path.join(library_path, \"hynetworkx\"))\n",
    "from src.data_preparer import filter_size, prepare_lp_data, get_time_filter_params,incidence_to_hyperedges, S_to_A\n",
    "from src.hypergraph_link_predictor import get_hypergraph_scores, hypergraph_score_abbr_map, all_hypergraph_score_names\n",
    "from src.link_predictor import get_perf_df\n",
    "from src.linkpred_predictor import get_linkpred_scores, predictor_abbr_map, all_predictor_names\n",
    "from src.supervised_link_predictor import classify\n",
    "from src.experimenter import perform_GWH_classification\n",
    "from src.incidence_matrix import parse_benson_incidence_matrix as parse_S\n",
    "from experimenter import *\n",
    "from experimenter import *\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from tqdm import tqdm_notebook\n",
    "from tabulate import tabulate\n",
    "from joblib import Memory\n",
    "import networkx as nx\n",
    "\n",
    "from scipy.sparse import csr_matrix, triu, hstack, find\n",
    "base_path = get_base_path()\n",
    "\n",
    "\n",
    "# We have S,G,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy_hypergraph():\n",
    "    I = [1, 5, 1, 5, 8, 2, 5, 6, 7, 1, 3, 5, 2, 6, 7, 8, 1, 5, 4, 1]\n",
    "    J = [1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7]\n",
    "    I = [i - 1 for i in I]\n",
    "    J = [j - 1 for j in J]\n",
    "    V = [1] * len(I)\n",
    "    S = csr_matrix((V, (I, J)))\n",
    "    return S\n",
    "G = nx.from_scipy_sparse_matrix(S_to_A(get_dummy_hypergraph(),False))\n",
    "# nx.draw(G, node_color='r', with_labels=True)\n",
    "hyperedge_times=[]\n",
    "for i in range(7):\n",
    "    hyperedge_times.append(0)\n",
    "hyperedge_times=np.array(hyperedge_times)\n",
    "S=get_dummy_hypergraph()\n",
    "def parse_s_w():\n",
    "    return S,hyperedge_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj=nx.adj_matrix(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 1, 1, 1, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 1, 1, 1, 1],\n",
       "        [1, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 1, 1, 1],\n",
       "        [0, 1, 0, 0, 1, 0, 1, 1],\n",
       "        [0, 1, 0, 0, 1, 1, 0, 1],\n",
       "        [1, 1, 0, 0, 1, 1, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 1, 0, 0, 0, 1, 1, 0],\n",
       "        [1, 0, 1, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 1, 0, 1, 1, 1],\n",
       "        [0, 1, 1, 0, 0, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 1, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj=((adj==0)*1)\n",
    "adj.setdiag(0)\n",
    "adj.eliminate_zeros()\n",
    "# adj.todense()\n",
    "A=adj\n",
    "A.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linkpred_scores1(lp_data, weighted,A,G, predictor_indices=None):\n",
    "    predictor_indices = predictor_indices or range(len(all_predictors))\n",
    "    predictors = [all_predictors[i] for i in predictor_indices]\n",
    "    predictor_names = [all_predictor_names[i] for i in predictor_indices]\n",
    "#     A_train = lp_data['A_train']\n",
    "#     A_test = lp_data['A_test']\n",
    "#     A_test_pos = lp_data['A_test_pos']\n",
    "#     A_test_neg = lp_data['A_test_neg']\n",
    "#     G_train = nx.from_scipy_sparse_matrix(A_train)\n",
    "    test_pairs = list(zip(*triu(A).nonzero()))\n",
    "    print(len(test_pairs))\n",
    "    scores = {}\n",
    "    if weighted:\n",
    "        for i in tqdm(range(len(predictors)), 'Predictor: '):\n",
    "            print(i)\n",
    "            predictor = predictors[i]\n",
    "            abbr = predictor_abbr_map[predictor_names[i]]\n",
    "            print('Preparing predictor {}'.format(abbr))\n",
    "            pred = predictor(G, strictly_included=test_pairs)\n",
    "            print('Performing prediction...')\n",
    "            try:\n",
    "                results = pred.predict(weight='weight')\n",
    "            except TypeError:\n",
    "                print(\"predict() got an unexpected keyword argument 'weight'\")\n",
    "                results = pred.predict()\n",
    "            print('Done')\n",
    "            scores[abbr] = {k: results[k] for k in test_pairs}\n",
    "        scores_df = pd.DataFrame(scores)\n",
    "    else:\n",
    "        for i in tqdm(range(len(predictors)), 'Predictor: '):\n",
    "            predictor = predictors[i]\n",
    "            abbr = predictor_abbr_map[predictor_names[i]]\n",
    "            print('Preparing predictor {}'.format(abbr))\n",
    "            pred = predictor(G, strictly_included=test_pairs)\n",
    "            print('Performing prediction...')\n",
    "            results = pred.predict()\n",
    "            print('Done')\n",
    "            scores[abbr] = {k: results[k] for k in test_pairs}\n",
    "        scores_df = pd.DataFrame(scores)\n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'S' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8c545e68cb8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweighted_lp_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_lp_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperedge_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlp_data_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rho'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlp_data_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'neg_factor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlp_data_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'neg_mode'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'S' is not defined"
     ]
    }
   ],
   "source": [
    "weighted_lp_data = prepare_lp_data(S, True, hyperedge_times, lp_data_params['rho'],lp_data_params['neg_factor'],lp_data_params['neg_mode'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_preparer import S_to_A, S_to_B, incidence_to_hyperedges, prepare_node_hyperneighbors_map\n",
    "\n",
    "def get_hypergraph_scores1(lp_data,A,S, score_indices=None):\n",
    "    score_indices = score_indices or range(len(all_hypergraph_score_names))\n",
    "    score_names = [all_hypergraph_score_names[i] for i in score_indices]\n",
    "    base_score_names = list({n[:-3] for n in score_names})\n",
    "#     S_train = lp_data['S_train']\n",
    "#     A_test_pos = lp_data['A_test_pos']\n",
    "#     A_test_neg = lp_data['A_test_neg']\n",
    "#     I, J = triu(A_test_pos + A_test_neg).nonzero()\n",
    "#     test_pairs = list(zip(I, J))\n",
    "    test_pairs = list(zip(*triu(A).nonzero()))\n",
    "\n",
    "    scores = {}\n",
    "    node_hynbrs_map = prepare_node_hyperneighbors_map(S)\n",
    "    for i in tqdm(range(len(base_score_names)), 'Hypergraph score: '):\n",
    "        # print(base_score_names)\n",
    "        base_name = base_score_names[i]\n",
    "        # print(base_name)\n",
    "        scoring_function = scoring_function_map[base_name]\n",
    "        print('Calculating hypergraph scores: {}'.format(base_name))\n",
    "        base_scores = scoring_function(test_pairs, S, node_hynbrs_map)\n",
    "        for prefix in base_scores:\n",
    "            score_name = base_name + prefix\n",
    "            # print(score_name)\n",
    "            abbr = hypergraph_score_abbr_map[score_name]\n",
    "            scores[abbr] = base_scores[prefix]\n",
    "    scores_df = pd.DataFrame(scores)\n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_link_prediction1(data_params, lp_data_params, lp_params=None, iter_var=0):\n",
    "    \"\"\"\n",
    "    data_params: {'data_name', 'base_path', 'split_mode', 'max_size_limit'}\n",
    "    lp_data_params: {'rho', 'neg_factor', 'neg_mode', 'weighted_flag'}\n",
    "    lp_params: {'linkpred_indices', 'hypergraph_score_indices'}\n",
    "\n",
    "    returns: (data, lp_data, lp_results)\n",
    "    \"\"\"\n",
    "    #print('READING DATASET...')\n",
    " #   data_name, base_path, split_mode, max_size_limit = [data_params[x] for x in\n",
    " #                                                       ['data_name', 'base_path', 'split_mode', 'max_size_limit']]\n",
    "\n",
    "\n",
    "    rho, neg_factor, neg_mode = [lp_data_params[x] for x in\n",
    "                                 ['rho', 'neg_factor', 'neg_mode']]\n",
    "\n",
    "    S, times = parse_s_w()\n",
    "    weighted_lp_data = prepare_lp_data(S, True, times, rho, neg_factor, neg_mode)\n",
    "    #print(weighted_lp_data)\n",
    "\n",
    "    #print('PERFORMING LINK PREDICTION...')\n",
    "    if lp_params:\n",
    "        linkpred_indices, hypergraph_score_indices = [lp_params[x] for x in\n",
    "                                                      ['linkpred_indices', 'hypergraph_score_indices']]\n",
    "    else:\n",
    "        linkpred_indices, hypergraph_score_indices = None, None\n",
    "    linkpred_indices=[0, 1, 2, 5, 6, 8, 10, 11, 12, 13]\n",
    "    hypergraph_score_indices=[8, 9, 11, 12, 30, 31, 33, 34, 52, 53, 55, 56, 37, 38, 40, 41, 14, 16, 17, 19, 20, 1, 2, 4, 5, 66, 67, 69, 70, 59, 60, 62, 63, 44, 45, 47, 48, 23, 24, 26, 27]\n",
    "    \n",
    "    weighted_linkpred_scores_df = get_linkpred_scores(weighted_lp_data, True, linkpred_indices)\n",
    "    unweighted_linkpred_scores_df = get_linkpred_scores(weighted_lp_data, False, linkpred_indices)\n",
    "    unweighted_linkpred_cols = list(unweighted_linkpred_scores_df.columns)\n",
    "    cols_map = {c: 'w_{}'.format(c) for c in unweighted_linkpred_cols}\n",
    "    weighted_linkpred_scores_df = weighted_linkpred_scores_df.rename(columns=cols_map)\n",
    "    weighted_linkpred_cols = list(weighted_linkpred_scores_df.columns)\n",
    "\n",
    "    hyg_scores_df = get_hypergraph_scores(weighted_lp_data, hypergraph_score_indices)\n",
    "    hyg_scores_cols = list(hyg_scores_df.columns)\n",
    "    scores_df = pd.merge(unweighted_linkpred_scores_df, weighted_linkpred_scores_df, left_index=True, right_index=True)\n",
    "    scores_df = pd.merge(scores_df, hyg_scores_df, left_index=True, right_index=True)\n",
    "    pos_pairs = set(zip(*weighted_lp_data['A_test_pos'].nonzero()))\n",
    "    scores_df['label'] = scores_df.index.map(lambda x: int(x in pos_pairs))\n",
    "    perf_df = get_perf_df(scores_df, unweighted_linkpred_cols + weighted_linkpred_cols, hyg_scores_cols)\n",
    "    return weighted_lp_data, \\\n",
    "           {'scores': scores_df, 'perf': perf_df}\n",
    "\n",
    "\n",
    "\n",
    "# a,b=perform_link_prediction1(data_params, lp_data_params, lp_params=lp_params, iter_var=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_classification1(data_params, lp_data_params, lp_params, classifier_params, iter_var=0):\n",
    "    _, lp_results= perform_link_prediction1(data_params, lp_data_params, lp_params, iter_var)\n",
    "    features, classifier = [classifier_params[x] for x in ['features', 'classifier']]\n",
    "    classifier_output = classify(lp_results, features, classifier, iter_var)\n",
    "    return classifier_output\n",
    "def perform_GWH_classification1(params, G_feats, W_feats, H_feats, classifier):\n",
    "    feat_combs = [G_feats, W_feats, H_feats, G_feats + H_feats, W_feats + H_feats]\n",
    "    params['classifier_params'] = {'classifier': classifier}\n",
    "    # print('Iterating over feature combinations...')\n",
    "    classifier_outputs = {}\n",
    "    for comb in (feat_combs):\n",
    "        params['classifier_params']['features'] = comb\n",
    "        classifier_outputs[tuple(comb)] = perform_classification1(params['data_params'],\n",
    "                                   params['lp_data_params'],\n",
    "                                   params['lp_params'],\n",
    "                                   params['classifier_params'],\n",
    "                                   params['iter_var'])\n",
    "    return classifier_outputs\n",
    "def classify(lp_results, predictor_cols, classifier, iter_var=0):\n",
    "    df = lp_results['scores'].copy(deep=True)\n",
    "\n",
    "    if predictor_cols is None:\n",
    "        predictor_cols = list(df.columns[:-1])\n",
    "\n",
    "    X, y = df.loc[:, predictor_cols], df.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=iter_var)\n",
    "\n",
    "    if classifier == 'xgboost':\n",
    "        # data_dmatrix = xgb.DMatrix(data=X_train, label=y_train)\n",
    "        xg_reg = xgb.XGBClassifier()\n",
    "        xg_reg.fit(X_train, y_train)\n",
    "\n",
    "        # test_preds = xg_reg.predict(X_test)\n",
    "        # train_preds = xg_reg.predict(X_train)\n",
    "\n",
    "        test_probs = [i[1] for i in xg_reg.predict_proba(X_test)]\n",
    "        train_probs = [i[1] for i in xg_reg.predict_proba(X_train)]\n",
    "\n",
    "        feat_imp_df = pd.DataFrame({'importance': dict(zip(list(X.columns), xg_reg.feature_importances_))})\n",
    "\n",
    "        train_col = '{}_{}'.format(classifier, 'train')\n",
    "        test_col = '{}_{}'.format(classifier, 'test')\n",
    "\n",
    "        test_df = df.loc[X_test.index, :]\n",
    "        train_df = df.loc[X_train.index, :]\n",
    "\n",
    "        train_df[train_col] = train_probs\n",
    "        test_df[test_col] = test_probs\n",
    "\n",
    "        train_perf_df = get_perf_df(train_df[[train_col, 'label']], [train_col], [])\n",
    "        test_perf_df = get_perf_df(test_df[[test_col, 'label']], [test_col], [])\n",
    "        return {'train_perf': train_perf_df,\n",
    "                'test_perf': test_perf_df,\n",
    "                'test_scores': test_df[[test_col]],\n",
    "                'feat_imp': feat_imp_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:genv] *",
   "language": "python",
   "name": "conda-env-genv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
