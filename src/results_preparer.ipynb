{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experimenter import *\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "mcm = mixed_combinations_map\n",
    "if 'HDPa' in mcm['PA']:\n",
    "    mcm['PA'].remove('HDPa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_clf_columns(lp_col, cols):\n",
    "    col_map = {}\n",
    "    for c in cols:\n",
    "        if len(c) == 1 and lp_col == c[0]:\n",
    "            col_map[c] = 'micro-G_{}'.format(lp_col)\n",
    "        elif len(c) == 1 and c[0].startswith('w_'):\n",
    "            col_map[c] = 'micro-W_{}'.format(lp_col)\n",
    "        elif len(c) == 4:\n",
    "            col_map[c] = 'micro-H_{}'.format(lp_col)\n",
    "        elif len(c) == 5 and lp_col in c:\n",
    "            col_map[c] = 'micro-GH_{}'.format(lp_col)\n",
    "        else:\n",
    "            col_map[c] = 'micro-WH_{}'.format(lp_col)\n",
    "    return col_map\n",
    "\n",
    "\n",
    "def to_mean_std(dfs):\n",
    "    df = pd.concat(dfs).reset_index().groupby('index').agg(list)\n",
    "    for c in df.columns:\n",
    "        df[c] = df[c].apply(lambda x: '{} $\\\\pm$ {}'.format(\"%.1f\" % round(np.mean(x), 1),\n",
    "                                               \"%.1f\" % round(np.std(x), 1)))\n",
    "    return df\n",
    "\n",
    "def get_overfit_score_df(train_df, test_df):\n",
    "    overfit_df = train_df.subtract(test_df)\n",
    "    overfit_df = overfit_df.div(train_df)\n",
    "    overfit_df = overfit_df.mul(100)\n",
    "    return overfit_df\n",
    "\n",
    "\n",
    "def get_perf_table(data_name, split_mode):\n",
    "    params = get_default_params()\n",
    "    params['data_params']['data_name'] = data_name\n",
    "    params['data_params']['split_mode'] = split_mode\n",
    "    params['data_params']['base_path'] = '/home2/e1-313-15477'\n",
    "    dfs, train_dfs, test_dfs, overfit_dfs = [], [], [], []\n",
    "    \n",
    "    for i in range(5):\n",
    "        params['iter_var'] = i\n",
    "        _, lp_results = perform_link_prediction(params['data_params'],\n",
    "            params['lp_data_params'],\n",
    "            params['lp_params'],\n",
    "            params['iter_var'])\n",
    "        cl_perfs = {}\n",
    "        interim_train_dfs = []\n",
    "        interim_test_dfs = []\n",
    "        for lp_col in tqdm(default_lp_cols):\n",
    "            G_feats = [lp_col]\n",
    "            W_feats = ['w_{}'.format(lp_col)]\n",
    "            H_feats = mcm[lp_col][1:]\n",
    "            output = perform_GWH_classification(params, G_feats, W_feats, H_feats, 'xgboost')\n",
    "            cl_perfs[lp_col] = output\n",
    "            train_df = pd.concat([output[k]['train_perf'].rename(columns = {'xgboost_train': k}).T for k in output]).T\n",
    "            test_df = pd.concat([output[k]['test_perf'].rename(columns = {'xgboost_test': k}).T for k in output]).T\n",
    "            clf_cols_map = prepare_clf_columns(lp_col, train_df.columns)\n",
    "            train_df.rename(columns = clf_cols_map, inplace=True)\n",
    "            test_df.rename(columns = clf_cols_map, inplace=True)\n",
    "            interim_train_dfs.append(train_df.T)\n",
    "            interim_test_dfs.append(test_df.T)\n",
    "        \n",
    "        train_df = pd.concat(interim_train_dfs).T\n",
    "        test_df = pd.concat(interim_test_dfs).T\n",
    "        overfit_df = get_overfit_score_df(train_df, test_df)\n",
    "        \n",
    "        train_dfs.append(train_df)\n",
    "        test_dfs.append(test_df)\n",
    "        overfit_dfs.append(overfit_df)\n",
    "        dfs.append(lp_results['perf'])\n",
    "\n",
    "    \n",
    "    df = to_mean_std(dfs)\n",
    "    train_df = to_mean_std(train_dfs)\n",
    "    test_df = to_mean_std(test_dfs)\n",
    "    overfit_df = to_mean_std(overfit_dfs)\n",
    "    return df, train_df, test_df, overfit_df\n",
    "\n",
    "\n",
    "def reformat_tables(df, train_df, test_df, overfit_df, metric):\n",
    "    GWH_cols = ['G', 'W', 'H_{max}', 'H_{avg}', 'H_{L1}', 'H_{L2}']\n",
    "    base_cols = ['micro-G', 'micro-W', 'micro-H', 'micro-GH', 'micro-WH']\n",
    "    rows = []\n",
    "    df_list = []\n",
    "    for c in default_lp_cols:\n",
    "        cols = [c, 'w_' + c] + mcm[c][1:]\n",
    "        row = df.loc[metric, cols]\n",
    "        row.name = c\n",
    "        rows.append(row)\n",
    "        df1 = pd.DataFrame(row).T\n",
    "        df1 = df1.rename(columns=dict(zip(df1.columns, GWH_cols)))\n",
    "        df_list.append(df1)\n",
    "        \n",
    "    rows = []\n",
    "    train_df_list = []\n",
    "    for c in default_lp_cols:\n",
    "        cols = ['{}_{}'.format(x, c) for x in base_cols]\n",
    "        row = train_df.loc[metric, cols]\n",
    "        row.name = c\n",
    "        rows.append(row)\n",
    "        df1 = pd.DataFrame(row).T\n",
    "        df1 = df1.rename(columns=dict(zip(df1.columns, base_cols)))\n",
    "        train_df_list.append(df1)\n",
    "        \n",
    "    rows = []\n",
    "    test_df_list = []\n",
    "    for c in default_lp_cols:\n",
    "        cols = ['{}_{}'.format(x, c) for x in base_cols]\n",
    "        row = test_df.loc[metric, cols]\n",
    "        row.name = c\n",
    "        rows.append(row)\n",
    "        df1 = pd.DataFrame(row).T\n",
    "        df1 = df1.rename(columns=dict(zip(df1.columns, base_cols)))\n",
    "        test_df_list.append(df1)\n",
    "    \n",
    "    rows = []\n",
    "    overfit_df_list = []\n",
    "    for c in default_lp_cols:\n",
    "        cols = ['{}_{}'.format(x, c) for x in base_cols]\n",
    "        row = overfit_df.loc[metric, cols]\n",
    "        row.name = c\n",
    "        rows.append(row)\n",
    "        df1 = pd.DataFrame(row).T\n",
    "        df1 = df1.rename(columns=dict(zip(df1.columns, base_cols)))\n",
    "        overfit_df_list.append(df1)\n",
    "    return pd.concat(df_list), pd.concat(train_df_list), pd.concat(test_df_list), pd.concat(overfit_df_list)\n",
    "\n",
    "\n",
    "def get_latex_table(df, file_name = None, bold_best=None, col_mode = 'math', ascending = True):\n",
    "    if col_mode == 'math':\n",
    "        table_df = df.rename(columns = {c: '${}$'.format(c) for c in df.columns})\n",
    "    elif col_mode == 'sf':\n",
    "        table_df = df.rename(columns = {c: '\\\\textsf{{{}}}'.format(c) for c in df.columns})\n",
    "    elif col_mode == 'tt':\n",
    "        table_df = df.rename(columns = {c: '\\\\texttt{{{}}}'.format(c) for c in df.columns})\n",
    "    if bold_best == 'per_col':\n",
    "        pass\n",
    "    elif bold_best == 'per_row':\n",
    "        for i in table_df.index:\n",
    "            max_i = table_df.loc[i, :].max() if ascending else table_df.loc[i, :].min()\n",
    "            table_df.loc[i, :] = table_df.loc[i, :].apply(lambda x: '\\\\textbf{{{}}}'.format(x) if x == max_i else x)\n",
    "    return table_df.to_latex(file_name, escape=False, column_format = 'l'+'c'*df.shape[1])\n",
    "\n",
    "def get_data_split_name(d, s, mode='full'):\n",
    "    if mode == 'full':\n",
    "        return '{} ({})'.format(d, s)\n",
    "    if mode == 'abbr':\n",
    "        return '{} ({})'.format(get_data_abbr(d), s[0])\n",
    "    if mode == 'idx':\n",
    "        return '{} ({})'.format(get_data_idx(d), s[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "from itertools import product\n",
    "data_names = [\n",
    "              'email-Enron',\n",
    "              'contact-high-school',\n",
    "              'NDC-substances',\n",
    "              'tags-math-sx',\n",
    "              'threads-math-sx',\n",
    "              'coauth-DBLP'\n",
    "             ]\n",
    "split_modes = [\n",
    "               'structural',\n",
    "               'temporal',\n",
    "              ]\n",
    "data_splits = list(product(data_names, split_modes))\n",
    "metrics = [\n",
    "#           'auc',\n",
    "#            'p@+',\n",
    "#            'r@+',\n",
    "           'p@100',\n",
    "          ]\n",
    "dfs = []\n",
    "for d, s in tqdm_notebook(data_splits):\n",
    "    base_folder = 'tables/perf/{}_{}/'.format(d, s)\n",
    "    mkdir_p(base_folder)\n",
    "    ds_name = '{} ({})'.format(get_data_abbr(d), s[0])\n",
    "    try:\n",
    "        df, train_df, test_df, overfit_df = get_perf_table(d, s)\n",
    "    except FileNotFoundError:\n",
    "        print('File Not Found')\n",
    "        continue\n",
    "    for m in metrics:\n",
    "        perf_table_df, train_perf_table_df, test_perf_table_df, overfit_table_df = reformat_tables(df, train_df, test_df, overfit_df, m)\n",
    "#         rank_df = perf_table_df.rank(axis=1, ascending=False)\n",
    "#         train_rank_df = train_perf_table_df.rank(axis=1, ascending=False)\n",
    "        test_rank_df = test_perf_table_df.rank(axis=1, ascending=False)\n",
    "        print(d, s, m)\n",
    "#         print('Standalone: ')\n",
    "#         file_name = '{}/standalone_{}.tex'.format(base_folder, m)\n",
    "#         print(tabulate(perf_table_df, headers='keys', tablefmt='psql'))\n",
    "#         get_latex_table(perf_table_df, file_name, bold_best = 'per_row')\n",
    "#         print(tabulate(rank_df.T[[ds_name]].T, headers='keys', tablefmt='psql'))\n",
    "#         print('Classifier Train: ')\n",
    "#         print(tabulate(train_perf_table_df, headers='keys', tablefmt='psql'))\n",
    "#         print(tabulate(train_rank_df, headers='keys', tablefmt='psql'))\n",
    "        print('Classifier Test: ')\n",
    "#         file_name = '{}/classifier_{}.tex'.format(base_folder, m)\n",
    "#         print(tabulate(test_perf_table_df, headers='keys', tablefmt='psql'))\n",
    "#         get_latex_table(test_perf_table_df, bold_best = 'per_row')\n",
    "        tabulate(test_rank_df, headers='keys', tablefmt='psql')\n",
    "        df = to_mean_std([test_rank_df.loc[i, :] for i in test_rank_df.index]).loc[test_rank_df.columns, :].rename(columns={0: get_data_split_name(d, s, mode='abbr')}).T\n",
    "        dfs.append(df)\n",
    "#         print('Overfit %: ')\n",
    "#         file_name = '{}/classifier_{}_overfit.tex'.format(base_folder, m)\n",
    "#         print(tabulate(overfit_table_df, headers='keys', tablefmt='psql'))\n",
    "#         get_latex_table(overfit_table_df, file_name)\n",
    "#         print('\\n\\n')\n",
    "table_df = pd.concat(dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tabulate(table_df.rank(axis=1, ascending=True), headers='keys', tablefmt='psql'))\n",
    "print(get_latex_table(table_df, bold_best = 'per_row', col_mode='tt', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'coauth-DBLP'\n",
    "_, _, test_df1, _ = reformat_tables(*get_perf_table(data_name, 'structural'), 'auc')\n",
    "_, _, test_df2, _ = reformat_tables(*get_perf_table(data_name, 'temporal'), 'auc')\n",
    "\n",
    "test_df = pd.concat([test_df1.rename(index={c: '{} ({})'.format(c, 's') for c in test_df1.index}),\n",
    "           test_df2.rename(index={c: '{} ({})'.format(c, 't') for c in test_df2.index})])\n",
    "print(get_latex_table(test_df, bold_best = 'per_row', col_mode='tt', ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
