{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experimenter import *\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "mcm = mixed_combinations_map\n",
    "if 'HDPa' in mcm['PA']:\n",
    "    mcm['PA'].remove('HDPa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_clf_columns(lp_col, cols):\n",
    "    col_map = {}\n",
    "    for c in cols:\n",
    "        if len(c) == 1 and lp_col == c[0]:\n",
    "            col_map[c] = 'micro-G_{}'.format(lp_col)\n",
    "        elif len(c) == 1 and c[0].startswith('w_'):\n",
    "            col_map[c] = 'micro-W_{}'.format(lp_col)\n",
    "        elif len(c) == 4:\n",
    "            col_map[c] = 'micro-H_{}'.format(lp_col)\n",
    "        elif len(c) == 5 and lp_col in c:\n",
    "            col_map[c] = 'micro-GH_{}'.format(lp_col)\n",
    "        else:\n",
    "            col_map[c] = 'micro-WH_{}'.format(lp_col)\n",
    "    return col_map\n",
    "\n",
    "\n",
    "def to_mean_std(dfs):\n",
    "    df = pd.concat(dfs).reset_index().groupby('index').agg(list)\n",
    "    for c in df.columns:\n",
    "        df[c] = df[c].apply(lambda x: '{} $\\\\pm$ {}'.format(\"%.1f\" % round(np.mean(x), 1),\n",
    "                                               \"%.1f\" % round(np.std(x), 1)))\n",
    "    return df\n",
    "\n",
    "def get_overfit_score_df(train_df, test_df):\n",
    "    overfit_df = train_df.subtract(test_df)\n",
    "    overfit_df = overfit_df.div(train_df)\n",
    "    overfit_df = overfit_df.mul(100)\n",
    "    return overfit_df\n",
    "\n",
    "\n",
    "def get_perf_table(data_name, split_mode):\n",
    "    params = get_default_params()\n",
    "    params['data_params']['data_name'] = data_name\n",
    "    params['data_params']['split_mode'] = split_mode\n",
    "    params['data_params']['base_path'] = '/home2/e1-313-15477'\n",
    "    dfs, train_dfs, test_dfs, overfit_dfs = [], [], [], []\n",
    "    \n",
    "    for i in range(5):\n",
    "        params['iter_var'] = i\n",
    "        _, lp_results = perform_link_prediction(params['data_params'],\n",
    "            params['lp_data_params'],\n",
    "            params['lp_params'],\n",
    "            params['iter_var'])\n",
    "        cl_perfs = {}\n",
    "        interim_train_dfs = []\n",
    "        interim_test_dfs = []\n",
    "        for lp_col in tqdm(default_lp_cols):\n",
    "            G_feats = [lp_col]\n",
    "            W_feats = ['w_{}'.format(lp_col)]\n",
    "            H_feats = mcm[lp_col][1:]\n",
    "            output = perform_GWH_classification(params, G_feats, W_feats, H_feats, 'xgboost')\n",
    "            cl_perfs[lp_col] = output\n",
    "            train_df = pd.concat([output[k]['train_perf'].rename(columns = {'xgboost_train': k}).T for k in output]).T\n",
    "            test_df = pd.concat([output[k]['test_perf'].rename(columns = {'xgboost_test': k}).T for k in output]).T\n",
    "            clf_cols_map = prepare_clf_columns(lp_col, train_df.columns)\n",
    "            train_df.rename(columns = clf_cols_map, inplace=True)\n",
    "            test_df.rename(columns = clf_cols_map, inplace=True)\n",
    "            interim_train_dfs.append(train_df.T)\n",
    "            interim_test_dfs.append(test_df.T)\n",
    "        \n",
    "        train_df = pd.concat(interim_train_dfs).T\n",
    "        test_df = pd.concat(interim_test_dfs).T\n",
    "        overfit_df = get_overfit_score_df(train_df, test_df)\n",
    "        \n",
    "        train_dfs.append(train_df)\n",
    "        test_dfs.append(test_df)\n",
    "        overfit_dfs.append(overfit_df)\n",
    "        dfs.append(lp_results['perf'])\n",
    "\n",
    "    \n",
    "    df = to_mean_std(dfs)\n",
    "    train_df = to_mean_std(train_dfs)\n",
    "    test_df = to_mean_std(test_dfs)\n",
    "    overfit_df = to_mean_std(overfit_dfs)\n",
    "    return df, train_df, test_df, overfit_df\n",
    "\n",
    "\n",
    "def reformat_tables(df, train_df, test_df, overfit_df, metric):\n",
    "    GWH_cols = ['G', 'W', 'H_{max}', 'H_{avg}', 'H_{L1}', 'H_{L2}']\n",
    "    base_cols = ['micro-G', 'micro-W', 'micro-H', 'micro-GH', 'micro-WH']\n",
    "    rows = []\n",
    "    df_list = []\n",
    "    for c in default_lp_cols:\n",
    "        cols = [c, 'w_' + c] + mcm[c][1:]\n",
    "        row = df.loc[metric, cols]\n",
    "        row.name = c\n",
    "        rows.append(row)\n",
    "        df1 = pd.DataFrame(row).T\n",
    "        df1 = df1.rename(columns=dict(zip(df1.columns, GWH_cols)))\n",
    "        df_list.append(df1)\n",
    "        \n",
    "    rows = []\n",
    "    train_df_list = []\n",
    "    for c in default_lp_cols:\n",
    "        cols = ['{}_{}'.format(x, c) for x in base_cols]\n",
    "        row = train_df.loc[metric, cols]\n",
    "        row.name = c\n",
    "        rows.append(row)\n",
    "        df1 = pd.DataFrame(row).T\n",
    "        df1 = df1.rename(columns=dict(zip(df1.columns, base_cols)))\n",
    "        train_df_list.append(df1)\n",
    "        \n",
    "    rows = []\n",
    "    test_df_list = []\n",
    "    for c in default_lp_cols:\n",
    "        cols = ['{}_{}'.format(x, c) for x in base_cols]\n",
    "        row = test_df.loc[metric, cols]\n",
    "        row.name = c\n",
    "        rows.append(row)\n",
    "        df1 = pd.DataFrame(row).T\n",
    "        df1 = df1.rename(columns=dict(zip(df1.columns, base_cols)))\n",
    "        test_df_list.append(df1)\n",
    "    \n",
    "    rows = []\n",
    "    overfit_df_list = []\n",
    "    for c in default_lp_cols:\n",
    "        cols = ['{}_{}'.format(x, c) for x in base_cols]\n",
    "        row = overfit_df.loc[metric, cols]\n",
    "        row.name = c\n",
    "        rows.append(row)\n",
    "        df1 = pd.DataFrame(row).T\n",
    "        df1 = df1.rename(columns=dict(zip(df1.columns, base_cols)))\n",
    "        overfit_df_list.append(df1)\n",
    "    return pd.concat(df_list), pd.concat(train_df_list), pd.concat(test_df_list), pd.concat(overfit_df_list)\n",
    "\n",
    "\n",
    "def get_latex_table(df, file_name = None, bold_best=None, col_mode = 'math', ascending = True):\n",
    "    if col_mode == 'math':\n",
    "        table_df = df.rename(columns = {c: '${}$'.format(c) for c in df.columns})\n",
    "    elif col_mode == 'sf':\n",
    "        table_df = df.rename(columns = {c: '\\\\textsf{{{}}}'.format(c) for c in df.columns})\n",
    "    elif col_mode == 'tt':\n",
    "        table_df = df.rename(columns = {c: '\\\\texttt{{{}}}'.format(c) for c in df.columns})\n",
    "    if bold_best == 'per_col':\n",
    "        pass\n",
    "    elif bold_best == 'per_row':\n",
    "        for i in table_df.index:\n",
    "            max_i = table_df.loc[i, :].max() if ascending else table_df.loc[i, :].min()\n",
    "            table_df.loc[i, :] = table_df.loc[i, :].apply(lambda x: '\\\\textbf{{{}}}'.format(x) if x == max_i else x)\n",
    "    return table_df.to_latex(file_name, escape=False, column_format = 'l'+'c'*df.shape[1])\n",
    "\n",
    "def get_data_split_name(d, s, mode='full'):\n",
    "    if mode == 'full':\n",
    "        return '{} ({})'.format(d, s)\n",
    "    if mode == 'abbr':\n",
    "        return '{} ({})'.format(get_data_abbr(d), s[0])\n",
    "    if mode == 'idx':\n",
    "        return '{} ({})'.format(get_data_idx(d), s[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3e477c17b542ada41c440d49784ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 19.88it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 21.06it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 21.85it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.67it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 21.68it/s]\n",
      "/home/govinds/.local/lib/python3.6/site-packages/ipykernel_launcher.py:18: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      " 20%|██        | 2/10 [00:00<00:00, 14.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email-Enron structural auc\n",
      "Classifier Test: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 15.30it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 15.91it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.84it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 21.54it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 21.15it/s]\n",
      " 30%|███       | 3/10 [00:00<00:00, 21.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email-Enron temporal auc\n",
      "Classifier Test: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 20.00it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 21.82it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 15.27it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 15.43it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 21.15it/s]\n",
      " 30%|███       | 3/10 [00:00<00:00, 20.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contact-high-school structural auc\n",
      "Classifier Test: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 17.68it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 19.37it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 21.45it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 17.11it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 19.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contact-high-school temporal auc\n",
      "Classifier Test: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "from itertools import product\n",
    "data_names = [\n",
    "              'email-Enron',\n",
    "              'contact-high-school',\n",
    "#               'NDC-substances',\n",
    "#               'tags-math-sx',\n",
    "#               'threads-math-sx',\n",
    "#               'coauth-DBLP'\n",
    "             ]\n",
    "split_modes = [\n",
    "               'structural',\n",
    "               'temporal',\n",
    "              ]\n",
    "data_splits = list(product(data_names, split_modes))\n",
    "metrics = [\n",
    "           'auc',\n",
    "#            'p@+',\n",
    "#            'r@+',\n",
    "#            'p@100',\n",
    "          ]\n",
    "dfs = []\n",
    "for d, s in tqdm_notebook(data_splits):\n",
    "    base_folder = 'tables/perf/{}_{}/'.format(d, s)\n",
    "    mkdir_p(base_folder)\n",
    "    ds_name = '{} ({})'.format(get_data_abbr(d), s[0])\n",
    "    try:\n",
    "        df, train_df, test_df, overfit_df = get_perf_table(d, s)\n",
    "    except FileNotFoundError:\n",
    "        print('File Not Found')\n",
    "        continue\n",
    "    for m in metrics:\n",
    "        perf_table_df, train_perf_table_df, test_perf_table_df, overfit_table_df = reformat_tables(df, train_df, test_df, overfit_df, m)\n",
    "#         rank_df = perf_table_df.rank(axis=1, ascending=False)\n",
    "#         train_rank_df = train_perf_table_df.rank(axis=1, ascending=False)\n",
    "        test_rank_df = test_perf_table_df.rank(axis=1, ascending=False)\n",
    "        print(d, s, m)\n",
    "#         print('Standalone: ')\n",
    "#         file_name = '{}/standalone_{}.tex'.format(base_folder, m)\n",
    "#         print(tabulate(perf_table_df, headers='keys', tablefmt='psql'))\n",
    "#         get_latex_table(perf_table_df, file_name, bold_best = 'per_row')\n",
    "#         print(tabulate(rank_df.T[[ds_name]].T, headers='keys', tablefmt='psql'))\n",
    "#         print('Classifier Train: ')\n",
    "#         print(tabulate(train_perf_table_df, headers='keys', tablefmt='psql'))\n",
    "#         print(tabulate(train_rank_df, headers='keys', tablefmt='psql'))\n",
    "        print('Classifier Test: ')\n",
    "#         file_name = '{}/classifier_{}.tex'.format(base_folder, m)\n",
    "#         print(tabulate(test_perf_table_df, headers='keys', tablefmt='psql'))\n",
    "#         get_latex_table(test_perf_table_df, bold_best = 'per_row')\n",
    "        tabulate(test_rank_df, headers='keys', tablefmt='psql')\n",
    "        df = to_mean_std([test_rank_df.loc[i, :] for i in test_rank_df.index]).loc[test_rank_df.columns, :].rename(columns={0: get_data_split_name(d, s, mode='abbr')}).T\n",
    "        dfs.append(df)\n",
    "#         print('Overfit %: ')\n",
    "#         file_name = '{}/classifier_{}_overfit.tex'.format(base_folder, m)\n",
    "#         print(tabulate(overfit_table_df, headers='keys', tablefmt='psql'))\n",
    "#         get_latex_table(overfit_table_df, file_name)\n",
    "#         print('\\n\\n')\n",
    "table_df = pd.concat(dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+-----------+-----------+------------+------------+\n",
      "|             |   micro-G |   micro-W |   micro-H |   micro-GH |   micro-WH |\n",
      "|-------------+-----------+-----------+-----------+------------+------------|\n",
      "| mail (s)    |         4 |         5 |         3 |          1 |          2 |\n",
      "| mail (t)    |         5 |         4 |         3 |          2 |          1 |\n",
      "| contact (s) |         4 |         5 |         3 |          2 |          1 |\n",
      "| contact (t) |         5 |         2 |         3 |          4 |          1 |\n",
      "+-------------+-----------+-----------+-----------+------------+------------+\n",
      "\\begin{tabular}{lccccc}\n",
      "\\toprule\n",
      "{} & \\texttt{micro-G} & \\texttt{micro-W} & \\texttt{micro-H} &       \\texttt{micro-GH} &       \\texttt{micro-WH} \\\\\n",
      "\\midrule\n",
      "mail (s)    &    3.6 $\\pm$ 0.5 &    5.0 $\\pm$ 0.0 &    3.2 $\\pm$ 0.7 &  \\textbf{1.4 $\\pm$ 0.5} &           1.8 $\\pm$ 0.7 \\\\\n",
      "mail (t)    &    4.8 $\\pm$ 0.4 &    4.1 $\\pm$ 0.5 &    3.0 $\\pm$ 0.4 &           2.0 $\\pm$ 0.4 &  \\textbf{1.1 $\\pm$ 0.3} \\\\\n",
      "contact (s) &    4.0 $\\pm$ 0.4 &    4.9 $\\pm$ 0.3 &    3.0 $\\pm$ 0.4 &           1.7 $\\pm$ 0.5 &  \\textbf{1.4 $\\pm$ 0.4} \\\\\n",
      "contact (t) &    3.7 $\\pm$ 1.1 &    3.0 $\\pm$ 1.5 &    3.3 $\\pm$ 1.2 &           3.6 $\\pm$ 1.1 &  \\textbf{1.4 $\\pm$ 0.5} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(table_df.rank(axis=1, ascending=True), headers='keys', tablefmt='psql'))\n",
    "print(get_latex_table(table_df, bold_best = 'per_row', col_mode='tt', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.36it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  8.58it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  8.33it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  8.99it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.84it/s]\n",
      "/home/govinds/.local/lib/python3.6/site-packages/ipykernel_launcher.py:18: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "100%|██████████| 10/10 [00:01<00:00,  8.79it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  8.99it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.19it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  8.93it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lccccc}\n",
      "\\toprule\n",
      "{} &         \\texttt{micro-G} &         \\texttt{micro-W} & \\texttt{micro-H} & \\texttt{micro-GH} & \\texttt{micro-WH} \\\\\n",
      "\\midrule\n",
      "AA (s)  &           92.7 $\\pm$ 0.6 &  \\textbf{92.3 $\\pm$ 1.1} &   93.1 $\\pm$ 0.7 &    93.2 $\\pm$ 0.8 &    94.1 $\\pm$ 0.9 \\\\\n",
      "AS (s)  &           90.0 $\\pm$ 1.6 &  \\textbf{83.5 $\\pm$ 1.6} &   93.2 $\\pm$ 0.9 &    93.5 $\\pm$ 0.9 &    93.0 $\\pm$ 0.8 \\\\\n",
      "CN (s)  &           92.3 $\\pm$ 0.5 &  \\textbf{91.2 $\\pm$ 0.9} &   91.9 $\\pm$ 1.3 &    93.3 $\\pm$ 0.8 &    93.0 $\\pm$ 1.0 \\\\\n",
      "Cos (s) &           93.3 $\\pm$ 0.7 &  \\textbf{91.7 $\\pm$ 1.6} &   93.5 $\\pm$ 0.9 &    93.9 $\\pm$ 0.5 &    93.8 $\\pm$ 0.9 \\\\\n",
      "PA (s)  &           71.7 $\\pm$ 3.6 &  \\textbf{67.9 $\\pm$ 4.6} &   70.5 $\\pm$ 4.1 &    73.1 $\\pm$ 2.9 &    72.9 $\\pm$ 3.8 \\\\\n",
      "JC (s)  &           93.4 $\\pm$ 1.0 &  \\textbf{92.0 $\\pm$ 1.3} &   93.4 $\\pm$ 0.9 &    93.8 $\\pm$ 0.9 &    94.2 $\\pm$ 0.7 \\\\\n",
      "MxO (s) &           93.2 $\\pm$ 1.0 &  \\textbf{91.4 $\\pm$ 1.0} &   93.6 $\\pm$ 0.9 &    93.8 $\\pm$ 0.6 &    94.0 $\\pm$ 0.4 \\\\\n",
      "MnO (s) &           92.5 $\\pm$ 0.3 &  \\textbf{88.4 $\\pm$ 0.9} &   93.1 $\\pm$ 1.3 &    93.4 $\\pm$ 0.8 &    92.8 $\\pm$ 0.8 \\\\\n",
      "NM (s)  &           93.6 $\\pm$ 0.5 &  \\textbf{91.5 $\\pm$ 0.9} &   93.3 $\\pm$ 1.0 &    93.6 $\\pm$ 0.8 &    93.8 $\\pm$ 0.8 \\\\\n",
      "Prn (s) &           91.5 $\\pm$ 1.5 &  \\textbf{89.6 $\\pm$ 1.0} &   93.4 $\\pm$ 0.9 &    93.9 $\\pm$ 0.6 &    93.8 $\\pm$ 0.7 \\\\\n",
      "AA (t)  &           71.4 $\\pm$ 2.6 &  \\textbf{68.6 $\\pm$ 3.2} &   75.4 $\\pm$ 2.2 &    76.1 $\\pm$ 2.0 &    81.0 $\\pm$ 2.1 \\\\\n",
      "AS (t)  &  \\textbf{65.3 $\\pm$ 2.4} &           66.5 $\\pm$ 1.4 &   70.7 $\\pm$ 1.7 &    71.1 $\\pm$ 2.6 &    71.0 $\\pm$ 1.8 \\\\\n",
      "CN (t)  &  \\textbf{60.0 $\\pm$ 1.4} &           63.2 $\\pm$ 1.6 &   67.8 $\\pm$ 2.3 &    68.7 $\\pm$ 1.2 &    78.9 $\\pm$ 1.1 \\\\\n",
      "Cos (t) &  \\textbf{62.7 $\\pm$ 2.1} &           68.5 $\\pm$ 2.3 &   70.4 $\\pm$ 2.6 &    72.1 $\\pm$ 2.4 &    75.2 $\\pm$ 1.6 \\\\\n",
      "PA (t)  &           57.6 $\\pm$ 1.6 &  \\textbf{57.2 $\\pm$ 1.8} &   72.7 $\\pm$ 1.1 &    72.9 $\\pm$ 1.7 &    74.3 $\\pm$ 1.4 \\\\\n",
      "JC (t)  &  \\textbf{59.5 $\\pm$ 2.3} &           63.9 $\\pm$ 2.6 &   71.3 $\\pm$ 2.0 &    71.3 $\\pm$ 2.1 &    73.4 $\\pm$ 1.1 \\\\\n",
      "MxO (t) &  \\textbf{62.3 $\\pm$ 1.1} &           62.6 $\\pm$ 1.1 &   70.6 $\\pm$ 2.0 &    72.3 $\\pm$ 1.9 &    72.8 $\\pm$ 1.1 \\\\\n",
      "MnO (t) &  \\textbf{69.6 $\\pm$ 2.3} &           73.2 $\\pm$ 1.7 &   71.2 $\\pm$ 2.6 &    73.2 $\\pm$ 2.6 &    74.4 $\\pm$ 1.5 \\\\\n",
      "NM (t)  &  \\textbf{60.6 $\\pm$ 2.2} &           63.1 $\\pm$ 1.6 &   71.2 $\\pm$ 2.4 &    71.1 $\\pm$ 3.1 &    73.1 $\\pm$ 2.3 \\\\\n",
      "Prn (t) &  \\textbf{61.7 $\\pm$ 2.4} &           66.9 $\\pm$ 2.3 &   68.2 $\\pm$ 2.6 &    69.0 $\\pm$ 2.3 &    72.7 $\\pm$ 1.5 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_name = 'email-Enron'\n",
    "_, _, test_df1, _ = reformat_tables(*get_perf_table(data_name, 'structural'), 'auc')\n",
    "_, _, test_df2, _ = reformat_tables(*get_perf_table(data_name, 'temporal'), 'auc')\n",
    "\n",
    "test_df = pd.concat([test_df1.rename(index={c: '{} ({})'.format(c, 's') for c in test_df1.index}),\n",
    "           test_df2.rename(index={c: '{} ({})'.format(c, 't') for c in test_df2.index})])\n",
    "print(get_latex_table(test_df, bold_best = 'per_row', col_mode='tt', ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
